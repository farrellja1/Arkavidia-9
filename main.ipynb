{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            category = os.path.splitext(filename)[0]\n",
    "            df['Category'] = category\n",
    "            dataframes.append(df)\n",
    "    if dataframes:\n",
    "        merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No CSV files found in the specified folder.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data2(base_folder_path):\n",
    "    dataframes = []\n",
    "    \n",
    "    for category in os.listdir(base_folder_path):\n",
    "        category_path = os.path.join(base_folder_path, category)\n",
    "        \n",
    "        if os.path.isdir(category_path):\n",
    "            for filename in os.listdir(category_path):\n",
    "                if filename.endswith('.csv'):\n",
    "                    file_path = os.path.join(category_path, filename)\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    df['Category'] = category\n",
    "                    province = os.path.splitext(filename)[0]\n",
    "                    df['Province'] = province\n",
    "                    price_columns = df.columns.difference(['Date', 'Category', 'Province'])\n",
    "                    if not price_columns.empty:\n",
    "                        df['Price'] = df[price_columns[0]]\n",
    "                    else:\n",
    "                        print(f\"No price column found in {filename}. Skipping this file.\")\n",
    "                        continue\n",
    "                    \n",
    "                    dataframes.append(df)\n",
    "    \n",
    "    if dataframes:\n",
    "        merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No CSV files found in the specified folder.\")\n",
    "        return pd.DataFrame()\n",
    "    merged_data2 = merged_data.pivot_table(index=['Date', 'Category'], columns='Province', values='Price', aggfunc='first')\n",
    "\n",
    "    merged_data2.reset_index(inplace=True)\n",
    "    merged_data2['Category'] = merged_data2['Category'].replace({\n",
    "    'bawang merah': 'Bawang Merah',\n",
    "    'bawang putih': 'Bawang Putih Bonggol',\n",
    "    'cabai merah': 'Cabai Merah Keriting',\n",
    "    'cabai rawit': 'Cabai Rawit Merah',\n",
    "    'daging ayam': 'Daging Ayam Ras',\n",
    "    'daging sapi': 'Daging Sapi Murni',\n",
    "    'gula': 'Gula Konsumsi',\n",
    "    'telur ayam': 'Telur Ayam Ras',\n",
    "    'tepung terigu': 'Tepung Terigu (Curah)',\n",
    "})\n",
    "    return merged_data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt(df, value_name):\n",
    "    melted = df.melt(id_vars=['Date', 'Category'], var_name='Province', value_name=value_name)\n",
    "    return melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df1, df2):\n",
    "    merged_data = pd.merge(df1, df2, on=['Date', 'Category', 'Province'], how='left')\n",
    "    for date in df2['Date'].unique():\n",
    "        beras_quantity = df2.loc[df2['Category'] == 'beras', 'Quantity'].loc[df2['Date'] == date].sum()\n",
    "    for category in ['Beras Medium', 'Beras Premium']:\n",
    "        merged_data.loc[(merged_data['Category'] == category) & (merged_data['Date'] == date), 'Quantity'] += beras_quantity\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(folder_path, base_folder_path):\n",
    "    data = load_data(folder_path)\n",
    "    data2 = load_data2(base_folder_path)\n",
    "    data_melted = melt(data, 'Price')\n",
    "    data2_melted = melt(data2, 'Quantity')\n",
    "    data_merged = merge(data_melted, data2_melted)\n",
    "    return data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\farel\\OneDrive\\Documents\\Arkavidia 9\\Harga Bahan Pangan\\train'\n",
    "folder_path2 = r'C:\\Users\\farel\\OneDrive\\Documents\\Arkavidia 9\\Google Trend'\n",
    "train = pipeline(folder_path, folder_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['Date'] =train['Date'].astype(int) // 10**9\n",
    "train['Category'] = train['Category'].astype('category')\n",
    "train['Province'] = train['Province'].astype('category')\n",
    "train = train.dropna(subset=['Price'])\n",
    "X = train.drop(columns=['Price'])\n",
    "y = train['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): True values.\n",
    "    y_pred (array-like): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated MAPE.\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10, enable_categorical=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(61.01411985040096)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36577.33 , 30581.002, 39282.984, ..., 26488.398, 26657.238,\n",
       "       29378.229], shape=(84518,), dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 558\n",
      "[LightGBM] [Info] Number of data points in the train set: 338071, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 36140.583753\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.309832040881665)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farel\\AppData\\Local\\Temp\\ipykernel_4776\\1790698691.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_data = pd.concat(dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "folder_test = r'C:\\Users\\farel\\OneDrive\\Documents\\Arkavidia 9\\Harga Bahan Pangan\\test'\n",
    "test = pipeline(folder_test, folder_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[305]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcb\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[32m      3\u001b[39m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[32m      4\u001b[39m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[32m      5\u001b[39m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[32m      6\u001b[39m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeaturesData\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFstrType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEShapCalcType\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFeaturesSelectionAlgorithm\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEFeaturesSelectionGrouping\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPool\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoost\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostClassifier\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostRegressor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatBoostRanker\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCatboostError\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMultiTargetCustomMetric\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMultiTargetCustomObjective\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py:45\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplot_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\plot_helpers.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[32m      6\u001b[39m fspath = _catboost.fspath\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtry_plot_offline\u001b[39m(figs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:1\u001b[39m, in \u001b[36minit _catboost\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import catboost as cb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
